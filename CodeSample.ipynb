{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ___________________________________________________________________________\n",
    "Code sample to be submitted to Wayfair.                                       .\n",
    "Created on Wed Dec.5.2018.                                                    .\n",
    "@author: Fakhteh Saadatniaki                                                  .\n",
    "                                                                              .\n",
    "Project: Aritificial Neural Network (ANN) to predict the apply rate on        .\n",
    "Glassdoor employment website with area under the curve (AUC) as metric of     .\n",
    "interest.                                                                     .\n",
    "                                                                              .\n",
    "Training and test data provided by a lead data scientist @ Glassdoor.         .\n",
    "\n",
    "Each row in the dataset corresponds to a user’s view of a job listing. It has .\n",
    "11 columns as described below.\n",
    "1) title_proximity_tfidf: Measures the closeness of query and job title.      .\n",
    "2) description_proximity_tfidf: Measures the closeness of query and job       .\n",
    "   description.                                                               .\n",
    "3) main_query_tfidf: A score related to user query closeness to job title and .\n",
    "   job description.                                                           .\n",
    "4) query_jl_score: Measures the popularity of query and job listing pair.     .\n",
    "5) query_title_score: Measures the popularity of query and job title pair.    .\n",
    "6) city_match: Indicates if the job listing matches to user/user-specified    .\n",
    "   location.                                                                  .\n",
    "7) job_age_days: Indicates the age of job listing posted.                     .\n",
    "8) apply: Indicates if the user has applied for this job listing.             .\n",
    "9) search_date_pacific: Date of the activity.                                 .\n",
    "10) u_id: ID of user (for privacy reasons ID is anonymized).                  .\n",
    "11) mgoc_id: Class ID of the job title clicked.                               .\n",
    "\n",
    "Training set: The examples with the “search date pacific” column (9-th column).\n",
    "              between 01/21/2018-01/26/2018.                                  .\n",
    "Test set: The examples with the “search date pacific” column (9-th column)    .\n",
    "              on 01/27/2018.                                                  .\n",
    "Inputs to the input layer::Features: First 7 columns.\n",
    "Label {0,1}: 8th column, i.e., apply.                                         .\n",
    "____________________________________________________________________________\"\"\"\n",
    "\n",
    "\"\"\" __________________________ Importing Modules ___________________________\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "\n",
    "\"\"\" ______________________ Preprocessing the Data __________________________\"\"\"\n",
    "filename = 'GlassdoorData.csv'\n",
    "raw_data = pd.read_csv(filename)\n",
    "num_features = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   ______________ Removing Examples with Missing Data ________________   '''\n",
    "raw_data_ = raw_data.replace({-1:np.nan}).dropna()\n",
    "raw_data_.to_csv('RawData.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   _________________________ Training Set ____________________________   '''\n",
    "train_flag = raw_data_['search_date_pacific'] == '2018-01-25'\n",
    "raw_data_train = raw_data_[train_flag]\n",
    "features_train = raw_data_train.iloc[:,0:num_features]\n",
    "# n_train = features_train.shape[0]\n",
    "ones_col_vec = np.ones(features_train.iloc[:,5].shape)\n",
    "#features_train = np.matrix(features_train.values)\n",
    "#ones_col_vec = np.ones(features_train[:,5].shape)\n",
    "#ones_col_vec = np.matrix(ones_col_vec)\n",
    "# Standardize all features except for the binary feature city_match\n",
    "for f in range(num_features):\n",
    "    if f !=5:\n",
    "        f_mean = np.mean(features_train.iloc[:,f])\n",
    "        #f_mean = np.mean(features_train[:,f])\n",
    "        features_train.iloc[:,f] = features_train.iloc[:,f] - f_mean*ones_col_vec\n",
    "        #features_train[:,f] = features_train[:,f] - f_mean*ones_col_vec\n",
    "        f_std = np.std(features_train.iloc[:,f])\n",
    "        #f_std = np.std(features_train[:,f])\n",
    "        features_train.iloc[:,f] = features_train.iloc[:,f]/f_std\n",
    "        #features_train[:,f] = features_train[:,f]/f_std\n",
    "\n",
    "features_train.insert(0,'bias',ones_col_vec)\n",
    "features_train.to_csv('TrainingFeat.csv', sep=',', encoding='utf-8')\n",
    "labels_train = raw_data_train.iloc[:,num_features]\n",
    "labels_train.to_csv('TrainingLabels.csv', sep=',', encoding='utf-8')\n",
    "#labels_train = labels_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   ____________________________ Test Set _____________________________   '''\n",
    "test_flag = raw_data_['search_date_pacific'] == '2018-01-27'\n",
    "raw_data_test = raw_data_[test_flag]\n",
    "features_test = raw_data_test.iloc[:,0:num_features]\n",
    "ones_col_vec = np.ones(features_test.iloc[:,5].shape)\n",
    "#features_test  = np.matrix(features_test.values)\n",
    "#ones_col_vec = np.matrix(np.ones(features_test[:,5].shape))\n",
    "# Standardize all features except for the binary feature city_match\n",
    "for f in range(num_features):\n",
    "    if f !=5:\n",
    "        f_mean = np.mean(features_test.iloc[:,f])\n",
    "        #f_mean = np.mean(features_test[:,f])\n",
    "        features_test.iloc[:,f] = features_test.iloc[:,f] - f_mean*ones_col_vec\n",
    "        #features_test[:,f] = features_test[:,f] - f_mean*ones_col_vec\n",
    "        f_std = np.std(features_test.iloc[:,f])\n",
    "        #f_std = np.std(features_test[:,f])\n",
    "        features_test.iloc[:,f] = features_test.iloc[:,f]/f_std\n",
    "        #features_test[:,f] = features_test[:,f]/f_std\n",
    "        \n",
    "features_test.insert(0,'bias',ones_col_vec)\n",
    "print(features_test)\n",
    "features_test.to_csv('TestFeat.csv', sep=',', encoding='utf-8')\n",
    "labels_test = raw_data_test.iloc[:,num_features]\n",
    "labels_test.to_csv('TestLabels.csv', sep=',', encoding='utf-8')\n",
    "#labels_test = labels_test.values\n",
    "yes_example = np.isin(labels_test,1) # True +\n",
    "no_example = np.isin(labels_test,0) # True - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"________________________ ReLU Activation Function _______________________\"\"\"     \n",
    "class ReLU:\n",
    "    @staticmethod\n",
    "    def activation(a):\n",
    "        a[a < 0] = 0\n",
    "        return a\n",
    "    @staticmethod\n",
    "    def deriv(a):\n",
    "        #a[a>0] = 1\n",
    "        return a>0\n",
    "\"\"\"_________________________________________________________________________\"\"\"\n",
    "\n",
    "\"\"\"______________________ Sigmoid Activation Function ______________________\"\"\"     \n",
    "class Sigmoid:\n",
    "    @staticmethod\n",
    "    def activation(a):\n",
    "        a = max(-50,a) # to avoid numerical issues\n",
    "        return 1 / (1 + np.exp(-a))\n",
    "    @staticmethod\n",
    "    def deriv(a):\n",
    "        return Sigmoid.activation(a) * (1 - Sigmoid.activation(a))\n",
    "\"\"\"_________________________________________________________________________\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"_______________________ Loss Function: Cross Entropy ____________________\"\"\"\n",
    "class CE:\n",
    "    def __init__(self, activ_fn):\n",
    "        '''\n",
    "        Args:\n",
    "            param activ_fn: Object of class activation function; e.g., \n",
    "            Sigmoid and ReLU\n",
    "        '''\n",
    "        self.activ_fn = activ_fn\n",
    "\n",
    "    def activation(self, a):\n",
    "        return self.activ_fn.activation(a)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(t, y):\n",
    "        '''\n",
    "        Args:\n",
    "            param t (int \\in {0,1}) True label.\n",
    "            param y (float \\in [0,1]):  Generated output, probability!\n",
    "        Return: \n",
    "            ce (flt): Cross entropy.\n",
    "        '''\n",
    "        ce = -(t*np.log(y)+(1-t)*np.log(1-y))\n",
    "        return ce\n",
    "\"\"\"_________________________________________________________________________\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ____________________ Artificial Neural Network Setup ______________________\n",
    "                                                                              .\n",
    "Input layer: | Hidden layer(s) | Output layer (P[Apply=1])|                   .\n",
    "     /\\                                                                       .\n",
    "     \\/            /\\                                                         . \n",
    "     /\\            \\/                                                         .\n",
    "     \\/            /\\                                 |`````````|             .\n",
    "     /\\            \\/                          /\\ __\\ |Threshold| />: Yes     .\n",
    "     \\/            /\\                          \\/   / |_________| \\<: No      .\n",
    "     /\\            \\/                                                         .\n",
    "     \\/            /\\                                                         .\n",
    "     /\\            \\/                                                         .\n",
    "     \\/            /\\                                                         .\n",
    "     /\\            \\/                                                         .\n",
    "     \\/            /\\                                                         .\n",
    "     /\\            \\/                                                         .\n",
    "     \\/                                                                       .\n",
    "7+1(bias) Neurons | n_h+1(bias) Neurons in hidden layer h | 1 Neuron          .\n",
    "____________________________________________________________________________\"\"\"\n",
    "class Network:\n",
    "    def __init__(self, dim, activ):\n",
    "        '''\n",
    "        Args:\n",
    "            param dim (any iterable): Dimensions of the neural net where the \n",
    "                elements at index i of the iterable denotes the number of nodes \n",
    "                in the corresponding layer: (num_features, n_1,...,n_H,n_o); \n",
    "                e.g., (7+1,n_1+1,1)\n",
    "            param activ (any iterable) : Activation function(s) to be applied \n",
    "                to neurons in the order of layers; e.g., ReLU for the hidden\n",
    "                layer and Sigmoid for the output layer.\n",
    "        Example architecture:\n",
    "        - Input layer: 8 Neurons\n",
    "        - One hidden layer: 6 Neurons\n",
    "        - Output layer: 1 Neuron\n",
    "        Layer               |  1      2         3\n",
    "        ------------------------------------------\n",
    "        # of neurons (dim)  | [8,     6,        1]\n",
    "        Activation (active) |       (Relu, Sigmoid)\n",
    "        '''\n",
    "        \n",
    "        self.num_layers = len(dim)\n",
    "        self.loss = None\n",
    "        self.learning_rate = None\n",
    "        \n",
    "        '''   _ Setup & Initialization of Weights,Biases, & Activations _   '''\n",
    "        # Keys are the layers with 1 being input, 2 hidden, and 3, the output.\n",
    "        self.W = {} # W={1:W[1] 2:W[2]}\n",
    "\n",
    "        self.activ = {} # active = {2:'ReLu', 3:'Sigmoid'}\n",
    "\n",
    "        for lay in range(len(dim) - 1):\n",
    "            self.W[lay + 1] = np.random.uniform(-0.1,0.1,(dim[lay+1],dim[lay]))\n",
    "            self.activ[lay + 2] = activ[lay] # no activation applied to inputs\n",
    "    '''_____________________________________________________________________'''\n",
    "    def _feed_forward(self, x):\n",
    "        '''\n",
    "        Forward propagation.\n",
    "        Args:\n",
    "            param x (2D array): Augmented input feature vector.\n",
    "        Return: \n",
    "            z(dict): Inputs or neuron activations\n",
    "            a(dict): weighted sum of inputs to a neuron\n",
    "            y (float): Predicted output, probability.\n",
    "        '''\n",
    "        # First layer has no activations and x is the augmented input:\n",
    "        z = {1: x}  \n",
    "        a = {}    \n",
    "\n",
    "        # Hidden layer weighted sums and activations:  \n",
    "        a[2] = np.dot(self.W[1],z[1])\n",
    "        z[2] = self.activ[2].activation(a[2])\n",
    "        z[2][0] = 1 # bias neuron\n",
    "        \n",
    "        # Output layer weighted sum and activation/predicted output:\n",
    "        a[3] = np.dot(self.W[2],z[2])\n",
    "        z[3] = self.activ[3].activation(a[3])\n",
    "        #y = z[3] # The predicted output for augmented feature vector x.\n",
    "        return z, a#, y\n",
    "    '''_____________________________________________________________________'''\n",
    "    def _back_prop(self, z, a, t):\n",
    "        '''\n",
    "        Args:\n",
    "        z = { 1: x,\n",
    "              2: ReLu(W[1]x)\n",
    "              3: Sigmoid(W[2]a[2]) | Predicted output\n",
    "              }\n",
    "        a = { 2: W[1]x\n",
    "              3: W[2]z[2]\n",
    "              }\n",
    "\n",
    "        param t(int \\in {0,1}) True label.\n",
    "        '''\n",
    "        \n",
    "        # Determine delta and partial derivative for the output layer:\n",
    "        delta = z[self.num_layers]-t\n",
    "        dw = delta * z[self.num_layers - 1].T\n",
    "\n",
    "        updates = {2 : dw}\n",
    "\n",
    "        '''Backpropagate the delta of output layer to obtain delta for each \n",
    "           neuron in the hidden layer and determine the partial derivative.'''\n",
    "        delta = np.multiply(np.dot(self.W[2].T,delta),self.activ[2].deriv(a[2]))\n",
    "        dw = np.outer(delta,z[1])\n",
    "        updates[1] = dw\n",
    "        \n",
    "    # Update the weights\n",
    "        for lay, dw in updates.items():\n",
    "            self._update_w_b(lay, dw)\n",
    "\n",
    "    def _update_w_b(self, layer, dw):\n",
    "        '''\n",
    "        Update weights and biases according to stochastic gradient descent.\n",
    "        Args:\n",
    "            param layer (int): Number of the layer\n",
    "            param delta_w (array): Partial derivatives of ce w.r.t. the weights\n",
    "            param delta (array): Delta error.\n",
    "        '''\n",
    "\n",
    "        self.W[layer] -= self.learning_rate * dw\n",
    "        \n",
    "    '''_____________________________________________________________________'''\n",
    "    def train(self, x_vec, t_vec, loss, epochs, learning_rate=1e-3):\n",
    "        \"\"\"\n",
    "        Train the neural network.\n",
    "        Args:\n",
    "        param x (2D array): Augmented feature vectors\n",
    "        param t (1D array): Containing biary labels.\n",
    "        param loss: Loss class (CrossEntropy in case of classification)\n",
    "        param epochs (int): Number of epochs for SGD.\n",
    "        param learning_rate (flt)\n",
    "        \"\"\"\n",
    "        if not x_vec.shape[0] == t_vec.shape[0]:\n",
    "            raise ValueError(\"Length of x and t arrays don't match\")\n",
    "        # Initiate the loss object with the final activation function\n",
    "        self.loss = loss(self.activ[self.num_layers])\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        for iter in range(epochs):\n",
    "            # Shuffle the data\n",
    "            shuffle = np.random.permutation(len(x_vec))\n",
    "            x_ = x_vec.iloc[shuffle]\n",
    "            t_ = t_vec.iloc[shuffle]\n",
    "\n",
    "            for ex in range(x_vec.shape[0]):\n",
    "                example = x_.iloc[ex,:]\n",
    "                z, a = self._feed_forward(example)\n",
    "                self._back_prop(z, a, t_.iloc[ex])\n",
    "            print(iter)\n",
    "            '''\n",
    "            if (iter + 1) % 10 == 0:\n",
    "                z, - = self._feed_forward(x)\n",
    "                print(\"Loss:\", self.loss.loss(t, z[self.n_layers]))\n",
    "            '''\n",
    "    def test(self, x_vec, threshold):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            param x (array) Augmented feature vectors\n",
    "            param threshold (float between 0 and 1)\n",
    "        Return:\n",
    "            y_pred (list) A 2D array of shape (n_test, {0,1}).\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for ex in range(x_vec.shape[0]):\n",
    "            z, a = self._feed_forward(x_vec.iloc[ex,:])\n",
    "            y_pred.append(z[self.num_layers]>threshold)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "nn = Network((8, 6, 1), (ReLU, Sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.train(features_train, labels_train, loss=CE, epochs=1, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = nn.test(features_test,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col':pred_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Pred.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
